{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmartSelection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6S97dB6uobGDnx9Oz+DTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunaCornejo/SmartGatewaySelection/blob/main/SmartSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZvUhxMPGyq-"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from geopy.distance import great_circle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN1VhBfZI-Kf",
        "outputId": "f46b0535-8e2c-483b-8d0f-5e76c939589f"
      },
      "source": [
        "#import git\n",
        "!git clone https://github.com/KunaCornejo/SmartGatewaySelection.git\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SmartGatewaySelection'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 33 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSxIFPN1JyUT",
        "outputId": "4e6b66d6-6ad9-4c0f-b1b6-230ed863ba14"
      },
      "source": [
        "ls 'SmartGatewaySelection'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c_n_ul.csv  Locaciones.csv  Matriz_Train_90.csv.zip  SmartSelection.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyI2ZPZnJ4BA"
      },
      "source": [
        "c_n_ul = genfromtxt('/content/SmartGatewaySelection/c_n_ul.csv', delimiter=',') \n",
        "c_n_ul=list(c_n_ul)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UfxiIBNXJim",
        "outputId": "37c6b5b9-a3ea-4bcd-99a3-015c58841d54"
      },
      "source": [
        "ubicaciones=['Panama','San Jose','Tegucigalpa','Mexico City','Monterrey','Guadalajara'\\\n",
        "             ,'Tijuana','La Habana','Sto. Domingo','San Salvador','San Juan',\\\n",
        "             'Torreon','La Paz (BC)','Veracruz','Cancun','Queretaro'\\\n",
        "             ,'Tuxtla (Gtz)','Cd. Juarez','San Pedro Sula','Belmopan','Kingston'\\\n",
        "             ,'Merida','Pto. Cabezas','Oaxaca']\n",
        "ubicaciones=np.transpose([ubicaciones])\n",
        "C_N_UL=np.array([c_n_ul],dtype=object) \n",
        "C_N_UL=np.transpose(C_N_UL)\n",
        "C_N_UL=np.delete(C_N_UL, 15, 0) #Get rid of Chihuahua, it is not necessary\n",
        "CN_UP=np.concatenate((ubicaciones,C_N_UL),axis=1) #Concatenate two lists\n",
        "print(CN_UP)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Panama' 32.4401636]\n",
            " ['San Jose' 32.4611016]\n",
            " ['Tegucigalpa' 32.4450513]\n",
            " ['Mexico City' 32.3918091]\n",
            " ['Monterrey' 32.313151]\n",
            " ['Guadalajara' 32.3588726]\n",
            " ['Tijuana' 32.0981607]\n",
            " ['La Habana' 32.3380601]\n",
            " ['Sto. Domingo' 32.2887155]\n",
            " ['San Salvador' 32.4521009]\n",
            " ['San Juan' 32.2438352]\n",
            " ['Torreon' 32.301041]\n",
            " ['La Paz (BC)' 32.2705558]\n",
            " ['Veracruz' 32.4018877]\n",
            " ['Cancun' 32.3779865]\n",
            " ['Queretaro' 32.3736176]\n",
            " ['Tuxtla (Gtz)' 32.4294244]\n",
            " ['Cd. Juarez' 32.195777]\n",
            " ['San Pedro Sula' 32.4354086]\n",
            " ['Belmopan' 32.4215586]\n",
            " ['Kingston' 32.3572017]\n",
            " ['Merida' 32.3851709]\n",
            " ['Pto. Cabezas' 32.4314209]\n",
            " ['Oaxaca' 32.4205395]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5qrAdeRX58y",
        "outputId": "9ec482ea-cce4-411e-f158-c56cf2529380"
      },
      "source": [
        "# Python code to sort the array using second element  \n",
        "# of sublist Function to sort using sorted() \n",
        "def Sort(sub_li): \n",
        "    # reverse = None (Sorts in Ascending order) \n",
        "    # key is set to sort using second element of  \n",
        "    # sublist lambda has been used \n",
        "    return(sorted(sub_li, key = lambda x: x[1], reverse = True)) \n",
        "    #X[] es la columna que vamos a ordenar\n",
        "# Driver Code \n",
        "sub_li = CN_UP\n",
        "sub_li= np.array(Sort(sub_li))  #Just test the sorted list \n",
        "print(sub_li)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['San Jose' 32.4611016]\n",
            " ['San Salvador' 32.4521009]\n",
            " ['Tegucigalpa' 32.4450513]\n",
            " ['Panama' 32.4401636]\n",
            " ['San Pedro Sula' 32.4354086]\n",
            " ['Pto. Cabezas' 32.4314209]\n",
            " ['Tuxtla (Gtz)' 32.4294244]\n",
            " ['Belmopan' 32.4215586]\n",
            " ['Oaxaca' 32.4205395]\n",
            " ['Veracruz' 32.4018877]\n",
            " ['Mexico City' 32.3918091]\n",
            " ['Merida' 32.3851709]\n",
            " ['Cancun' 32.3779865]\n",
            " ['Queretaro' 32.3736176]\n",
            " ['Guadalajara' 32.3588726]\n",
            " ['Kingston' 32.3572017]\n",
            " ['La Habana' 32.3380601]\n",
            " ['Monterrey' 32.313151]\n",
            " ['Torreon' 32.301041]\n",
            " ['Sto. Domingo' 32.2887155]\n",
            " ['La Paz (BC)' 32.2705558]\n",
            " ['San Juan' 32.2438352]\n",
            " ['Cd. Juarez' 32.195777]\n",
            " ['Tijuana' 32.0981607]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_6vdNvsamZ3"
      },
      "source": [
        "#Unzip the .csv file\n",
        "import zipfile #import ZipFile\n",
        "with zipfile.ZipFile('/content/SmartGatewaySelection/Matriz_Train_90.csv.zip','r') as zip_ref:\n",
        "    zip_ref.extractall('content')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbxHR2PKYnC8"
      },
      "source": [
        "#It is imported the predicted rain attenuation matrix obtained from Deep Learning Model \n",
        "Matrix_Arain = genfromtxt('content/Matriz_Train_90.csv', delimiter=',')\n",
        "Matrix_Arain = np.delete(Matrix_Arain, 15, 0) #Get rid of Chihuahua, it is not necessary"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn-u_mbxb2cl"
      },
      "source": [
        "#The CNIR Matrix is padding by zeros in order to load values later.\n",
        "CNIR=np.zeros((len(CN_UP[:,0]),len(Matrix_Arain[0,:])),dtype=float)\n",
        "Y=np.zeros((len(CN_UP[:,0]),len(Matrix_Arain[0,:])),dtype=int) \n",
        "prob=np.zeros((len(CN_UP[:,0]),1),dtype=float)  #Array 24x1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1P_SuXp1xiz"
      },
      "source": [
        "CI_co = 36.09  #C/I co-channel at 50 GHz (offset-paraboli-reflctor antenna simulations)\n",
        "CI_adj = 38.17 #C/I adjacent at 50 Ghz\n",
        "trh = 14.00    #CNIR Threshold\n",
        "\n",
        "#CNIR [C/(N+I)] calculations for each feeder link at time-step t+1 \n",
        "#(due to the predicted rain attenuation)\n",
        "#Further, it calculates every feeder link availability \n",
        "\n",
        "for i in range(len(CN_UP[:,0])):\n",
        "    CNIR[i,:]=CN_UP[i,1]-Matrix_Arain[i,0:]\n",
        "    CNIR[i,:]=10*np.log10(1/(1/(np.power(10,CNIR[i,0:]/10))+1/(np.power(10,CI_co/10))\\\n",
        "        +1/(np.power(10,CI_adj/10))))     \n",
        "    for j in range(len(CNIR[i,0:])):\n",
        "        if CNIR[i,j]>=trh: \n",
        "            Y[i,j]=1\n",
        "    prob[i,0]=sum(Y[i,0:])/len(Y[i,0:])\n",
        "Y=np.array(Y,dtype=object)\n",
        "estado = np.concatenate((ubicaciones,prob,Y),axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6-xFLZyAsjf",
        "outputId": "aa7d7e8c-646d-4f91-d3e8-0fcd5bdf5c87"
      },
      "source": [
        "#To obtain geographic coordinates from each location in order to find\n",
        "#the distance matrix D\n",
        "sites = genfromtxt('/content/SmartGatewaySelection/Locaciones.csv', delimiter=',') \n",
        "sites=np.array(sites,dtype=float)\n",
        "sites=np.delete(sites, 15, 0) #Get rid of Chihuahua, it is not necessary\n",
        "#Creamos Matriz de Distancias entre ubicaciones\n",
        "D=np.zeros((len(sites[0:,0]),len(sites[0:,0])),dtype=float)\n",
        "\n",
        "for i in range(len(sites[0:,0])):\n",
        "    for j in range(len(sites[0:,0])):\n",
        "        D[i,j]=great_circle((sites[i,0],sites[i,1]),(sites[j,0],sites[j,1])).kilometers\n",
        "\n",
        "D=np.array(D,dtype=object)\n",
        "D_tag = np.concatenate((ubicaciones,D),axis=1) #Columna de encabezados\n",
        "ubic = ubicaciones.tolist() #Convierte un array en una lista\n",
        "ubic.insert(0,[''])\n",
        "ubic = np.transpose(ubic)\n",
        "D_tag = np.concatenate((ubic,D_tag),axis=0) #Fila de encabezados\n",
        "\n",
        "#To save the distance matrix D\n",
        "#np.savetxt('.../Distance.csv',D_tag,fmt='%s',delimiter=',')\n",
        "print('done')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYor8gauCJfb",
        "outputId": "e60218df-acb8-4f83-af58-77c48af899f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#La siguiente fase es ordenar las ubicaciones ordenando primero por probabilidades\n",
        "#y luego ordenamos por distancias > d (km) según el número N de estaciones nominales\n",
        "\n",
        "N=4         #Número de Estaciones N nominales, Con N=4, d=125.. da 3963 cortes con el CNIR combinado y 2035 con el CNIR uplink normal (ambos con trh=16.55 dB)\n",
        "d_trh=80   #Umbral de distancia mínimo\n",
        "\n",
        "nominal_matrix=np.zeros((N,len(estado[0,0:])),dtype=object)\n",
        "redundant_matrix=np.zeros(((len(estado[0:,0])-N),len(estado[0,0:])),dtype=object)\n",
        "\n",
        "estado_ordenado = np.array(Sort(estado))\n",
        "#np.savetxt('/Volumes/Macintosh HD/Users/andrescornejo/Documents/Doctorado/Python/Cap6-Paper/Ordenado.csv',estado_ordenado[:,0:2],fmt='%s',delimiter=',')\n",
        "\n",
        "nominal_matrix=estado_ordenado[0:N,0:]\n",
        "redundant_matrix=estado_ordenado[N:,0:]\n",
        "\n",
        "filas = [' ']\n",
        "contador=0\n",
        "while (filas[0] == ' '):\n",
        "    contador+=1\n",
        "    for k in range(0,N):\n",
        "        site_ini=nominal_matrix[k,0]\n",
        "        i=list(D_tag[0,0:]).index(site_ini)\n",
        "        print(f'\\nAnalizamos el sitio: {site_ini}\\n')\n",
        "        for l in range(0,N):\n",
        "            site_comp=nominal_matrix[l,0]\n",
        "                    \n",
        "            j=list(D_tag[0:,0]).index(site_comp)\n",
        "    \n",
        "            if ((k==l) & (D_tag[i,j]==0)):\n",
        "                print(f'No se analiza el mismo sitio: {site_comp}')\n",
        "            elif ((k!=l) & (D_tag[i,j]>=d_trh)):\n",
        "                print(f'Cumple la condición de distancia hacia {site_comp}: {D_tag[i,j]}')\n",
        "            elif ((k!=l) & (D_tag[i,j]<d_trh)):\n",
        "                print(f'No Cumple la condición de distancia hacia {site_comp}: {D_tag[i,j]}')\n",
        "                filas.append(l)\n",
        "        \n",
        "    if len(filas)>1:\n",
        "        print('\\nIntercambio de Filas')\n",
        "        filas=list(dict.fromkeys(filas)) #Elimina elementos repetidos dentro del array\n",
        "        \n",
        "        redundant_matrix_res=redundant_matrix #Respaldamos Nominal Matrix\n",
        "        \n",
        "        for n in range(0,len(filas)-1):\n",
        "            #Enviamos al final de la matriz redundante\n",
        "            redundant_matrix=np.insert(redundant_matrix,len(estado)-N,nominal_matrix[filas[n+1],0:],axis=0)\n",
        "            #Intercambiamos el no valida de la matriz nominal con el mejor redundante en probabilidad\n",
        "            nominal_matrix[filas[n+1],0:] = redundant_matrix_res[n,0:]\n",
        "            #borramos la fila del apoyo redundante \n",
        "            redundant_matrix=np.delete(redundant_matrix,0, axis=0)\n",
        "        filas.clear()\n",
        "        filas = [' ']\n",
        "    else:\n",
        "        print(f'\\nTodos los sitios Cumplen con la Distancia, D>{d_trh} km\\n')\n",
        "        filas.clear()\n",
        "        filas.insert(0,'done')\n",
        "        \n",
        "nominal_matrix=np.array(Sort(nominal_matrix))\n",
        "redundant_matrix=np.array(Sort(redundant_matrix))\n",
        "\n",
        "print(nominal_matrix)\n",
        "print(redundant_matrix)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Analizamos el sitio: Torreon\n",
            "\n",
            "No se analiza el mismo sitio: Torreon\n",
            "Cumple la condición de distancia hacia Cd. Juarez: 754.8701336424568\n",
            "\n",
            "Analizamos el sitio: Cd. Juarez\n",
            "\n",
            "Cumple la condición de distancia hacia Torreon: 754.8701336424568\n",
            "No se analiza el mismo sitio: Cd. Juarez\n",
            "\n",
            "Todos los sitios Cumplen con la Distancia, D>80 km\n",
            "\n",
            "[['Torreon' 0.9994425418569254 1 ... 1 1 1]\n",
            " ['Cd. Juarez' 0.9992161339421614 1 ... 1 1 1]]\n",
            "[['La Paz (BC)' 0.9991552511415525 1 ... 1 1 1]\n",
            " ['Tijuana' 0.9989554794520548 1 ... 1 1 1]\n",
            " ['Oaxaca' 0.9986111111111111 1 ... 1 1 1]\n",
            " ...\n",
            " ['San Juan' 0.9902226027397261 1 ... 1 1 1]\n",
            " ['Panama' 0.9898439878234399 1 ... 1 1 1]\n",
            " ['Pto. Cabezas' 0.9888831811263318 1 ... 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}